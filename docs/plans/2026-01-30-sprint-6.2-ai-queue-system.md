# Sprint 6.2: AI Queue System Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Create a background worker that polls for pending AI jobs, processes them using Ollama Cloud, and provides admin visibility into queue status.

**Architecture:** Repository pattern for AiQueue table operations. Background worker starts on app boot via Next.js instrumentation, polls every 10 seconds, processes one job at a time using the existing Ollama Cloud client (which has built-in retry logic). API routes for job submission and status. Admin UI shows queue statistics.

**Tech Stack:** TypeScript, Prisma, Next.js instrumentation.ts, pino logger

---

## Task 1: AI Queue Repository

**Files:**
- Create: `packages/database/src/repositories/ai-queue.ts`
- Modify: `packages/database/src/repositories/index.ts`

**Step 1: Create the repository**

Create `packages/database/src/repositories/ai-queue.ts`:

```typescript
import { db } from '../client';

import type { Prisma } from '@prisma/client';

// =============================================================================
// Types
// =============================================================================

export type AiQueueStatus = 'pending' | 'processing' | 'completed' | 'failed';
export type AiRequestType = 'post_generation' | 'newsletter_intro' | 'content_summary';

export interface AiQueueRecord {
  id: string;
  userId: string | null;
  requestType: string;
  inputData: Record<string, unknown>;
  status: string;
  result: Record<string, unknown> | null;
  errorMessage: string | null;
  attempts: number;
  maxAttempts: number;
  createdAt: Date;
  processedAt: Date | null;
}

export interface CreateAiQueueData {
  userId?: string;
  requestType: AiRequestType;
  inputData: {
    prompt: string;
    system?: string;
    context?: Record<string, unknown>;
  };
  maxAttempts?: number;
}

export interface FindAllAiQueueOptions {
  status?: AiQueueStatus;
  requestType?: AiRequestType;
  userId?: string;
  page?: number;
  limit?: number;
}

export interface AiQueueStats {
  pending: number;
  processing: number;
  completed: number;
  failed: number;
  total: number;
}

// =============================================================================
// Repository
// =============================================================================

export const aiQueueRepository = {
  /**
   * Create a new AI job
   */
  async create(data: CreateAiQueueData): Promise<AiQueueRecord> {
    const record = await db.aiQueue.create({
      data: {
        userId: data.userId,
        requestType: data.requestType,
        inputData: data.inputData as Prisma.InputJsonValue,
        maxAttempts: data.maxAttempts ?? 3,
      },
    });

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Find a job by ID
   */
  async findById(id: string): Promise<AiQueueRecord | null> {
    const record = await db.aiQueue.findUnique({
      where: { id },
    });

    if (!record) return null;

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Find the oldest pending job (for worker)
   */
  async findPending(): Promise<AiQueueRecord | null> {
    const record = await db.aiQueue.findFirst({
      where: { status: 'pending' },
      orderBy: { createdAt: 'asc' },
    });

    if (!record) return null;

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Mark job as processing and increment attempts
   */
  async markProcessing(id: string): Promise<AiQueueRecord> {
    const record = await db.aiQueue.update({
      where: { id },
      data: {
        status: 'processing',
        attempts: { increment: 1 },
      },
    });

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Mark job as completed with result
   */
  async markCompleted(id: string, result: Record<string, unknown>): Promise<AiQueueRecord> {
    const record = await db.aiQueue.update({
      where: { id },
      data: {
        status: 'completed',
        result: result as Prisma.InputJsonValue,
        processedAt: new Date(),
      },
    });

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Mark job as failed with error message
   */
  async markFailed(id: string, errorMessage: string): Promise<AiQueueRecord> {
    const record = await db.aiQueue.update({
      where: { id },
      data: {
        status: 'failed',
        errorMessage,
        processedAt: new Date(),
      },
    });

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Reset job to pending (for retry after processing failure)
   */
  async resetToPending(id: string): Promise<AiQueueRecord> {
    const record = await db.aiQueue.update({
      where: { id },
      data: {
        status: 'pending',
      },
    });

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Cancel a pending job
   */
  async cancel(id: string): Promise<AiQueueRecord | null> {
    const job = await this.findById(id);
    if (!job || job.status !== 'pending') {
      return null;
    }

    const record = await db.aiQueue.update({
      where: { id },
      data: {
        status: 'failed',
        errorMessage: 'Cancelled by user',
        processedAt: new Date(),
      },
    });

    return {
      ...record,
      inputData: record.inputData as Record<string, unknown>,
      result: record.result as Record<string, unknown> | null,
    };
  },

  /**
   * Find all jobs with pagination and filters
   */
  async findAll(options: FindAllAiQueueOptions = {}): Promise<{
    jobs: AiQueueRecord[];
    pagination: { page: number; limit: number; total: number; totalPages: number };
  }> {
    const { status, requestType, userId, page = 1, limit = 20 } = options;

    const where: Prisma.AiQueueWhereInput = {};
    if (status) where.status = status;
    if (requestType) where.requestType = requestType;
    if (userId) where.userId = userId;

    const [total, records] = await Promise.all([
      db.aiQueue.count({ where }),
      db.aiQueue.findMany({
        where,
        orderBy: { createdAt: 'desc' },
        skip: (page - 1) * limit,
        take: limit,
      }),
    ]);

    return {
      jobs: records.map(record => ({
        ...record,
        inputData: record.inputData as Record<string, unknown>,
        result: record.result as Record<string, unknown> | null,
      })),
      pagination: {
        page,
        limit,
        total,
        totalPages: Math.ceil(total / limit),
      },
    };
  },

  /**
   * Get queue statistics
   */
  async getStats(): Promise<AiQueueStats> {
    const [pending, processing, completed, failed] = await Promise.all([
      db.aiQueue.count({ where: { status: 'pending' } }),
      db.aiQueue.count({ where: { status: 'processing' } }),
      db.aiQueue.count({ where: { status: 'completed' } }),
      db.aiQueue.count({ where: { status: 'failed' } }),
    ]);

    return {
      pending,
      processing,
      completed,
      failed,
      total: pending + processing + completed + failed,
    };
  },

  /**
   * Delete old completed/failed jobs (cleanup)
   */
  async cleanup(olderThanDays: number = 30): Promise<number> {
    const cutoff = new Date();
    cutoff.setDate(cutoff.getDate() - olderThanDays);

    const result = await db.aiQueue.deleteMany({
      where: {
        status: { in: ['completed', 'failed'] },
        processedAt: { lt: cutoff },
      },
    });

    return result.count;
  },
};
```

**Step 2: Add exports to index**

Add to `packages/database/src/repositories/index.ts`:

```typescript
export {
  aiQueueRepository,
  type AiQueueStatus,
  type AiRequestType,
  type AiQueueRecord,
  type CreateAiQueueData,
  type FindAllAiQueueOptions,
  type AiQueueStats,
} from './ai-queue';
```

**Step 3: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 4: Commit**

```bash
git add packages/database/src/repositories/ai-queue.ts packages/database/src/repositories/index.ts
git commit -m "feat(ai): add AI queue repository"
```

---

## Task 2: Queue Worker

**Files:**
- Create: `apps/admin/lib/ai/queue-worker.ts`
- Modify: `apps/admin/lib/ai/index.ts`

**Step 1: Create the queue worker**

Create `apps/admin/lib/ai/queue-worker.ts`:

```typescript
/**
 * AI Queue Worker
 * Background worker that polls for pending jobs and processes them
 */

import { aiQueueRepository } from '@repo/database';

import { aiLogger } from '../logger';

import { generate, isOllamaCloudConfigured } from './ollama-cloud';

import type { AiQueueRecord } from '@repo/database';

// =============================================================================
// Configuration
// =============================================================================

const POLL_INTERVAL_MS = 10_000; // 10 seconds
const WORKER_ENABLED = process.env.AI_WORKER_ENABLED !== 'false';

let workerInterval: ReturnType<typeof setInterval> | null = null;
let isProcessing = false;

// =============================================================================
// Worker Logic
// =============================================================================

/**
 * Process a single job
 */
async function processJob(job: AiQueueRecord): Promise<void> {
  aiLogger.info({ jobId: job.id, requestType: job.requestType }, 'Processing AI job');

  // Mark as processing
  await aiQueueRepository.markProcessing(job.id);

  try {
    const inputData = job.inputData as { prompt: string; system?: string };

    // Call Ollama Cloud (has built-in retry logic)
    const result = await generate(inputData.prompt, {
      system: inputData.system,
    });

    if (result.success) {
      // Mark as completed
      await aiQueueRepository.markCompleted(job.id, {
        response: result.data.response,
        model: result.data.model,
        promptTokens: result.data.prompt_eval_count,
        completionTokens: result.data.eval_count,
      });

      aiLogger.info({ jobId: job.id }, 'AI job completed successfully');
    } else {
      // Check if we should retry or fail permanently
      const updatedJob = await aiQueueRepository.findById(job.id);

      if (updatedJob && updatedJob.attempts < updatedJob.maxAttempts) {
        // Reset to pending for retry
        await aiQueueRepository.resetToPending(job.id);
        aiLogger.warn(
          { jobId: job.id, attempts: updatedJob.attempts, maxAttempts: updatedJob.maxAttempts, error: result.error },
          'AI job failed, will retry'
        );
      } else {
        // Max attempts reached, mark as failed
        await aiQueueRepository.markFailed(job.id, result.error.message);
        aiLogger.error(
          { jobId: job.id, error: result.error },
          'AI job failed permanently after max attempts'
        );
      }
    }
  } catch (error) {
    // Unexpected error
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    await aiQueueRepository.markFailed(job.id, errorMessage);
    aiLogger.error({ jobId: job.id, error }, 'AI job failed with unexpected error');
  }
}

/**
 * Poll for and process pending jobs
 */
async function pollAndProcess(): Promise<void> {
  // Skip if already processing or not configured
  if (isProcessing) {
    return;
  }

  if (!isOllamaCloudConfigured()) {
    return;
  }

  isProcessing = true;

  try {
    // Find oldest pending job
    const job = await aiQueueRepository.findPending();

    if (job) {
      await processJob(job);
    }
  } catch (error) {
    aiLogger.error({ error }, 'Error in queue worker poll cycle');
  } finally {
    isProcessing = false;
  }
}

// =============================================================================
// Public API
// =============================================================================

/**
 * Start the queue worker
 * Should be called once when the app starts
 */
export function startQueueWorker(): void {
  if (!WORKER_ENABLED) {
    aiLogger.info('AI queue worker disabled via AI_WORKER_ENABLED=false');
    return;
  }

  if (workerInterval) {
    aiLogger.warn('AI queue worker already running');
    return;
  }

  aiLogger.info({ pollIntervalMs: POLL_INTERVAL_MS }, 'Starting AI queue worker');

  // Initial poll
  void pollAndProcess();

  // Start polling interval
  workerInterval = setInterval(() => {
    void pollAndProcess();
  }, POLL_INTERVAL_MS);
}

/**
 * Stop the queue worker
 */
export function stopQueueWorker(): void {
  if (workerInterval) {
    clearInterval(workerInterval);
    workerInterval = null;
    aiLogger.info('AI queue worker stopped');
  }
}

/**
 * Check if worker is running
 */
export function isWorkerRunning(): boolean {
  return workerInterval !== null;
}

/**
 * Manually trigger processing (for testing/admin)
 */
export async function triggerProcessing(): Promise<{ processed: boolean; jobId?: string }> {
  if (!isOllamaCloudConfigured()) {
    return { processed: false };
  }

  const job = await aiQueueRepository.findPending();

  if (!job) {
    return { processed: false };
  }

  await processJob(job);
  return { processed: true, jobId: job.id };
}
```

**Step 2: Update AI module exports**

Update `apps/admin/lib/ai/index.ts`:

```typescript
/**
 * AI services module
 * - Ollama Cloud: LLM text generation (deepseek-v3.2)
 * - Queue Worker: Background job processing
 * - Local Ollama: Embeddings (nomic-embed-text) - handled separately in search
 */

// Ollama Cloud client
export {
  isOllamaCloudConfigured,
  getConfiguredModel,
  listModels,
  generate,
  checkHealth,
} from './ollama-cloud';

// Queue worker
export {
  startQueueWorker,
  stopQueueWorker,
  isWorkerRunning,
  triggerProcessing,
} from './queue-worker';

// Types
export type {
  OllamaCloudConfig,
  OllamaGenerateRequest,
  OllamaGenerateResponse,
  OllamaHealthStatus,
  OllamaModelsResponse,
  AiResponse,
  AiResult,
  AiError,
} from './types';
```

**Step 3: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 4: Commit**

```bash
git add apps/admin/lib/ai/queue-worker.ts apps/admin/lib/ai/index.ts
git commit -m "feat(ai): add queue worker for background job processing"
```

---

## Task 3: Start Worker on App Boot

**Files:**
- Create: `apps/admin/instrumentation.ts`

**Step 1: Create instrumentation file**

Create `apps/admin/instrumentation.ts`:

```typescript
/**
 * Next.js Instrumentation
 * Runs once when the server starts
 * https://nextjs.org/docs/app/building-your-application/optimizing/instrumentation
 */

export async function register() {
  // Only run on server
  if (process.env.NEXT_RUNTIME === 'nodejs') {
    const { startQueueWorker } = await import('./lib/ai/queue-worker');
    startQueueWorker();
  }
}
```

**Step 2: Enable instrumentation in next.config**

Check if `apps/admin/next.config.ts` has instrumentation enabled. If not, it's enabled by default in Next.js 15+.

**Step 3: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 4: Commit**

```bash
git add apps/admin/instrumentation.ts
git commit -m "feat(ai): start queue worker on app boot via instrumentation"
```

---

## Task 4: Queue API Routes - Submit & List

**Files:**
- Create: `apps/admin/app/api/ai/queue/route.ts`

**Step 1: Create queue routes**

Create `apps/admin/app/api/ai/queue/route.ts`:

```typescript
import { aiQueueRepository } from '@repo/database';
import { NextResponse } from 'next/server';
import { z } from 'zod';

import { requireAuth } from '@/lib/api-auth';
import { apiError, apiSuccess } from '@/lib/api-response';

import type { AiRequestType } from '@repo/database';

// =============================================================================
// Validation
// =============================================================================

const createJobSchema = z.object({
  requestType: z.enum(['post_generation', 'newsletter_intro', 'content_summary']),
  prompt: z.string().min(1, 'Prompt je obavezan'),
  system: z.string().optional(),
  context: z.record(z.unknown()).optional(),
});

const listQuerySchema = z.object({
  status: z.enum(['pending', 'processing', 'completed', 'failed']).optional(),
  requestType: z.enum(['post_generation', 'newsletter_intro', 'content_summary']).optional(),
  page: z.coerce.number().int().min(1).default(1),
  limit: z.coerce.number().int().min(1).max(100).default(20),
});

// =============================================================================
// POST /api/ai/queue - Submit new job
// =============================================================================

export async function POST(request: Request) {
  const session = await requireAuth();
  if (!session) {
    return apiError('UNAUTHORIZED', 'Unauthorized', 401);
  }

  try {
    const body = await request.json();
    const result = createJobSchema.safeParse(body);

    if (!result.success) {
      return apiError('VALIDATION_ERROR', result.error.errors[0]?.message || 'Invalid input', 400);
    }

    const { requestType, prompt, system, context } = result.data;

    const job = await aiQueueRepository.create({
      userId: session.user.id,
      requestType: requestType as AiRequestType,
      inputData: {
        prompt,
        system,
        context,
      },
    });

    return apiSuccess(job, 201);
  } catch (error) {
    console.error('Failed to create AI job:', error);
    return apiError('SERVER_ERROR', 'Greška pri kreiranju AI zadatka', 500);
  }
}

// =============================================================================
// GET /api/ai/queue - List jobs
// =============================================================================

export async function GET(request: Request) {
  const session = await requireAuth();
  if (!session) {
    return apiError('UNAUTHORIZED', 'Unauthorized', 401);
  }

  try {
    const { searchParams } = new URL(request.url);
    const query = listQuerySchema.safeParse({
      status: searchParams.get('status') || undefined,
      requestType: searchParams.get('requestType') || undefined,
      page: searchParams.get('page') || 1,
      limit: searchParams.get('limit') || 20,
    });

    if (!query.success) {
      return apiError('VALIDATION_ERROR', 'Invalid query parameters', 400);
    }

    const { jobs, pagination } = await aiQueueRepository.findAll({
      status: query.data.status,
      requestType: query.data.requestType,
      page: query.data.page,
      limit: query.data.limit,
    });

    return NextResponse.json({
      success: true,
      data: jobs,
      pagination,
    });
  } catch (error) {
    console.error('Failed to list AI jobs:', error);
    return apiError('SERVER_ERROR', 'Greška pri dohvaćanju AI zadataka', 500);
  }
}
```

**Step 2: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 3: Commit**

```bash
git add apps/admin/app/api/ai/queue/route.ts
git commit -m "feat(ai): add queue API routes for job submission and listing"
```

---

## Task 5: Queue API Routes - Single Job & Cancel

**Files:**
- Create: `apps/admin/app/api/ai/queue/[id]/route.ts`

**Step 1: Create single job routes**

Create `apps/admin/app/api/ai/queue/[id]/route.ts`:

```typescript
import { aiQueueRepository } from '@repo/database';

import { requireAuth } from '@/lib/api-auth';
import { apiError, apiSuccess } from '@/lib/api-response';

interface RouteParams {
  params: Promise<{ id: string }>;
}

// =============================================================================
// GET /api/ai/queue/[id] - Get single job
// =============================================================================

export async function GET(request: Request, { params }: RouteParams) {
  const session = await requireAuth();
  if (!session) {
    return apiError('UNAUTHORIZED', 'Unauthorized', 401);
  }

  try {
    const { id } = await params;
    const job = await aiQueueRepository.findById(id);

    if (!job) {
      return apiError('NOT_FOUND', 'AI zadatak nije pronađen', 404);
    }

    return apiSuccess(job);
  } catch (error) {
    console.error('Failed to get AI job:', error);
    return apiError('SERVER_ERROR', 'Greška pri dohvaćanju AI zadatka', 500);
  }
}

// =============================================================================
// DELETE /api/ai/queue/[id] - Cancel pending job
// =============================================================================

export async function DELETE(request: Request, { params }: RouteParams) {
  const session = await requireAuth();
  if (!session) {
    return apiError('UNAUTHORIZED', 'Unauthorized', 401);
  }

  try {
    const { id } = await params;
    const job = await aiQueueRepository.cancel(id);

    if (!job) {
      return apiError('BAD_REQUEST', 'Samo zadaci na čekanju mogu biti otkazani', 400);
    }

    return apiSuccess({ message: 'AI zadatak je otkazan' });
  } catch (error) {
    console.error('Failed to cancel AI job:', error);
    return apiError('SERVER_ERROR', 'Greška pri otkazivanju AI zadatka', 500);
  }
}
```

**Step 2: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 3: Commit**

```bash
git add apps/admin/app/api/ai/queue/\[id\]/route.ts
git commit -m "feat(ai): add single job and cancel API routes"
```

---

## Task 6: Queue Stats API Route

**Files:**
- Create: `apps/admin/app/api/ai/queue/stats/route.ts`

**Step 1: Create stats route**

Create `apps/admin/app/api/ai/queue/stats/route.ts`:

```typescript
import { aiQueueRepository } from '@repo/database';

import { requireAuth } from '@/lib/api-auth';
import { apiError, apiSuccess } from '@/lib/api-response';
import { isOllamaCloudConfigured, isWorkerRunning } from '@/lib/ai';

// =============================================================================
// GET /api/ai/queue/stats - Get queue statistics
// =============================================================================

export async function GET() {
  const session = await requireAuth();
  if (!session) {
    return apiError('UNAUTHORIZED', 'Unauthorized', 401);
  }

  try {
    const stats = await aiQueueRepository.getStats();

    return apiSuccess({
      ...stats,
      workerRunning: isWorkerRunning(),
      ollamaConfigured: isOllamaCloudConfigured(),
    });
  } catch (error) {
    console.error('Failed to get queue stats:', error);
    return apiError('SERVER_ERROR', 'Greška pri dohvaćanju statistike', 500);
  }
}
```

**Step 2: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 3: Commit**

```bash
git add apps/admin/app/api/ai/queue/stats/route.ts
git commit -m "feat(ai): add queue stats API route"
```

---

## Task 7: Manual Process Trigger API

**Files:**
- Create: `apps/admin/app/api/ai/queue/process/route.ts`

**Step 1: Create process trigger route**

Create `apps/admin/app/api/ai/queue/process/route.ts`:

```typescript
import { requireAuth } from '@/lib/api-auth';
import { apiError, apiSuccess } from '@/lib/api-response';
import { triggerProcessing, isOllamaCloudConfigured } from '@/lib/ai';

// =============================================================================
// POST /api/ai/queue/process - Manually trigger job processing
// =============================================================================

export async function POST() {
  const session = await requireAuth();
  if (!session) {
    return apiError('UNAUTHORIZED', 'Unauthorized', 401);
  }

  // Only super_admin and admin can manually trigger
  if (session.user.role !== 'super_admin' && session.user.role !== 'admin') {
    return apiError('FORBIDDEN', 'Nemate dozvolu za ovu akciju', 403);
  }

  if (!isOllamaCloudConfigured()) {
    return apiError('BAD_REQUEST', 'Ollama Cloud nije konfiguriran', 400);
  }

  try {
    const result = await triggerProcessing();

    if (result.processed) {
      return apiSuccess({
        message: 'Zadatak je obrađen',
        jobId: result.jobId,
      });
    } else {
      return apiSuccess({
        message: 'Nema zadataka na čekanju',
      });
    }
  } catch (error) {
    console.error('Failed to trigger processing:', error);
    return apiError('SERVER_ERROR', 'Greška pri obradi zadatka', 500);
  }
}
```

**Step 2: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 3: Commit**

```bash
git add apps/admin/app/api/ai/queue/process/route.ts
git commit -m "feat(ai): add manual process trigger API route"
```

---

## Task 8: Admin Queue Status Page

**Files:**
- Create: `apps/admin/app/(dashboard)/ai/page.tsx`
- Create: `apps/admin/app/(dashboard)/ai/ai-queue-status.tsx`

**Step 1: Create page wrapper**

Create `apps/admin/app/(dashboard)/ai/page.tsx`:

```typescript
import { Suspense } from 'react';

import { AiQueueStatus } from './ai-queue-status';

export const metadata = {
  title: 'AI | Admin',
};

export default function AiPage() {
  return (
    <div className="space-y-6">
      <div>
        <h1 className="font-display text-2xl font-bold text-neutral-900">AI Sustav</h1>
        <p className="mt-1 text-neutral-600">
          Pregled AI zadataka i statusa sustava
        </p>
      </div>

      <Suspense fallback={<div className="animate-pulse h-96 bg-neutral-100 rounded-lg" />}>
        <AiQueueStatus />
      </Suspense>
    </div>
  );
}
```

**Step 2: Create status component**

Create `apps/admin/app/(dashboard)/ai/ai-queue-status.tsx`:

```typescript
'use client';

import {
  Badge,
  Button,
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
  toast,
} from '@repo/ui';
import {
  AlertCircle,
  CheckCircle2,
  Clock,
  Loader2,
  Play,
  RefreshCw,
  XCircle,
} from 'lucide-react';
import { useCallback, useEffect, useState } from 'react';

interface QueueStats {
  pending: number;
  processing: number;
  completed: number;
  failed: number;
  total: number;
  workerRunning: boolean;
  ollamaConfigured: boolean;
}

interface QueueJob {
  id: string;
  requestType: string;
  status: string;
  errorMessage: string | null;
  attempts: number;
  maxAttempts: number;
  createdAt: string;
  processedAt: string | null;
}

const STATUS_ICONS = {
  pending: Clock,
  processing: Loader2,
  completed: CheckCircle2,
  failed: XCircle,
};

const STATUS_COLORS = {
  pending: 'bg-amber-100 text-amber-800',
  processing: 'bg-blue-100 text-blue-800',
  completed: 'bg-green-100 text-green-800',
  failed: 'bg-red-100 text-red-800',
};

const STATUS_LABELS = {
  pending: 'Na čekanju',
  processing: 'U obradi',
  completed: 'Završeno',
  failed: 'Neuspjelo',
};

const TYPE_LABELS: Record<string, string> = {
  post_generation: 'Generiranje objave',
  newsletter_intro: 'Newsletter uvod',
  content_summary: 'Sažetak sadržaja',
};

export function AiQueueStatus() {
  const [stats, setStats] = useState<QueueStats | null>(null);
  const [recentJobs, setRecentJobs] = useState<QueueJob[]>([]);
  const [isLoading, setIsLoading] = useState(true);
  const [isProcessing, setIsProcessing] = useState(false);

  const fetchData = useCallback(async () => {
    try {
      const [statsRes, jobsRes] = await Promise.all([
        fetch('/api/ai/queue/stats'),
        fetch('/api/ai/queue?limit=10'),
      ]);

      if (statsRes.ok) {
        const statsData = await statsRes.json();
        setStats(statsData.data);
      }

      if (jobsRes.ok) {
        const jobsData = await jobsRes.json();
        setRecentJobs(jobsData.data);
      }
    } catch (error) {
      console.error('Failed to fetch queue data:', error);
    } finally {
      setIsLoading(false);
    }
  }, []);

  useEffect(() => {
    void fetchData();

    // Auto-refresh every 10 seconds
    const interval = setInterval(() => {
      void fetchData();
    }, 10_000);

    return () => clearInterval(interval);
  }, [fetchData]);

  const handleManualProcess = useCallback(async () => {
    setIsProcessing(true);
    try {
      const res = await fetch('/api/ai/queue/process', { method: 'POST' });
      const data = await res.json();

      if (res.ok) {
        toast({ title: 'Uspjeh', description: data.data.message });
        void fetchData();
      } else {
        toast({ title: 'Greška', description: data.error?.message, variant: 'destructive' });
      }
    } catch (error) {
      toast({ title: 'Greška', description: 'Obrada nije uspjela', variant: 'destructive' });
    } finally {
      setIsProcessing(false);
    }
  }, [fetchData]);

  if (isLoading) {
    return (
      <div className="flex items-center justify-center py-12">
        <Loader2 className="h-8 w-8 animate-spin text-primary-600" />
      </div>
    );
  }

  return (
    <div className="space-y-6">
      {/* System Status */}
      <div className="grid gap-4 md:grid-cols-2">
        <Card>
          <CardHeader className="pb-2">
            <CardTitle className="text-sm font-medium">Ollama Cloud</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="flex items-center gap-2">
              {stats?.ollamaConfigured ? (
                <>
                  <CheckCircle2 className="h-5 w-5 text-green-600" />
                  <span className="text-green-600 font-medium">Konfigurirano</span>
                </>
              ) : (
                <>
                  <AlertCircle className="h-5 w-5 text-amber-600" />
                  <span className="text-amber-600 font-medium">Nije konfigurirano</span>
                </>
              )}
            </div>
          </CardContent>
        </Card>

        <Card>
          <CardHeader className="pb-2">
            <CardTitle className="text-sm font-medium">Worker Status</CardTitle>
          </CardHeader>
          <CardContent>
            <div className="flex items-center gap-2">
              {stats?.workerRunning ? (
                <>
                  <div className="h-2 w-2 rounded-full bg-green-500 animate-pulse" />
                  <span className="text-green-600 font-medium">Aktivan</span>
                </>
              ) : (
                <>
                  <div className="h-2 w-2 rounded-full bg-neutral-400" />
                  <span className="text-neutral-600 font-medium">Neaktivan</span>
                </>
              )}
            </div>
          </CardContent>
        </Card>
      </div>

      {/* Queue Stats */}
      <Card>
        <CardHeader>
          <div className="flex items-center justify-between">
            <div>
              <CardTitle>Red čekanja</CardTitle>
              <CardDescription>Statistika AI zadataka</CardDescription>
            </div>
            <div className="flex gap-2">
              <Button variant="outline" size="sm" onClick={() => void fetchData()}>
                <RefreshCw className="h-4 w-4 mr-1" />
                Osvježi
              </Button>
              <Button
                size="sm"
                onClick={() => void handleManualProcess()}
                disabled={isProcessing || !stats?.ollamaConfigured || stats?.pending === 0}
              >
                {isProcessing ? (
                  <Loader2 className="h-4 w-4 mr-1 animate-spin" />
                ) : (
                  <Play className="h-4 w-4 mr-1" />
                )}
                Obradi jedan
              </Button>
            </div>
          </div>
        </CardHeader>
        <CardContent>
          <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
            <div className="text-center p-4 rounded-lg bg-amber-50">
              <div className="text-3xl font-bold text-amber-600">{stats?.pending ?? 0}</div>
              <div className="text-sm text-amber-700">Na čekanju</div>
            </div>
            <div className="text-center p-4 rounded-lg bg-blue-50">
              <div className="text-3xl font-bold text-blue-600">{stats?.processing ?? 0}</div>
              <div className="text-sm text-blue-700">U obradi</div>
            </div>
            <div className="text-center p-4 rounded-lg bg-green-50">
              <div className="text-3xl font-bold text-green-600">{stats?.completed ?? 0}</div>
              <div className="text-sm text-green-700">Završeno</div>
            </div>
            <div className="text-center p-4 rounded-lg bg-red-50">
              <div className="text-3xl font-bold text-red-600">{stats?.failed ?? 0}</div>
              <div className="text-sm text-red-700">Neuspjelo</div>
            </div>
          </div>
        </CardContent>
      </Card>

      {/* Recent Jobs */}
      <Card>
        <CardHeader>
          <CardTitle>Nedavni zadaci</CardTitle>
          <CardDescription>Zadnjih 10 AI zadataka</CardDescription>
        </CardHeader>
        <CardContent>
          {recentJobs.length === 0 ? (
            <div className="text-center py-8 text-neutral-500">
              Nema zadataka u redu čekanja
            </div>
          ) : (
            <div className="space-y-3">
              {recentJobs.map(job => {
                const StatusIcon = STATUS_ICONS[job.status as keyof typeof STATUS_ICONS] || Clock;
                const isSpinning = job.status === 'processing';

                return (
                  <div
                    key={job.id}
                    className="flex items-center justify-between p-3 rounded-lg border border-neutral-200"
                  >
                    <div className="flex items-center gap-3">
                      <StatusIcon
                        className={`h-5 w-5 ${isSpinning ? 'animate-spin text-blue-600' : ''}`}
                      />
                      <div>
                        <div className="font-medium">
                          {TYPE_LABELS[job.requestType] || job.requestType}
                        </div>
                        <div className="text-sm text-neutral-500">
                          {new Date(job.createdAt).toLocaleString('hr-HR')}
                          {job.attempts > 1 && ` · Pokušaj ${job.attempts}/${job.maxAttempts}`}
                        </div>
                        {job.errorMessage && (
                          <div className="text-sm text-red-600 mt-1">{job.errorMessage}</div>
                        )}
                      </div>
                    </div>
                    <Badge className={STATUS_COLORS[job.status as keyof typeof STATUS_COLORS]}>
                      {STATUS_LABELS[job.status as keyof typeof STATUS_LABELS] || job.status}
                    </Badge>
                  </div>
                );
              })}
            </div>
          )}
        </CardContent>
      </Card>
    </div>
  );
}
```

**Step 3: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 4: Commit**

```bash
git add apps/admin/app/\(dashboard\)/ai/
git commit -m "feat(ai): add admin queue status page"
```

---

## Task 9: Add AI to Sidebar Navigation

**Files:**
- Modify: `apps/admin/config/navigation.ts`

**Step 1: Add AI navigation item**

Add `Brain` icon import and AI navigation item to `apps/admin/config/navigation.ts`.

Find the imports and add:
```typescript
import { Brain } from 'lucide-react';
```

Add a new section after "Komunikacija" (or wherever appropriate):
```typescript
{
  title: 'AI',
  items: [
    {
      title: 'AI Sustav',
      href: '/ai',
      icon: icon(Brain),
    },
  ],
},
```

**Step 2: Verify**

Run: `pnpm type-check`
Expected: PASS

**Step 3: Commit**

```bash
git add apps/admin/config/navigation.ts
git commit -m "feat(ai): add AI section to admin sidebar"
```

---

## Task 10: Unit Tests for Queue Worker

**Files:**
- Create: `apps/admin/lib/ai/__tests__/queue-worker.test.ts`

**Step 1: Create test file**

Create `apps/admin/lib/ai/__tests__/queue-worker.test.ts`:

```typescript
import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';

// Mock the dependencies before importing
vi.mock('@repo/database', () => ({
  aiQueueRepository: {
    findPending: vi.fn(),
    markProcessing: vi.fn(),
    markCompleted: vi.fn(),
    markFailed: vi.fn(),
    resetToPending: vi.fn(),
    findById: vi.fn(),
  },
}));

vi.mock('../ollama-cloud', () => ({
  generate: vi.fn(),
  isOllamaCloudConfigured: vi.fn(),
}));

vi.mock('../../logger', () => ({
  aiLogger: {
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn(),
  },
}));

import { aiQueueRepository } from '@repo/database';

import { generate, isOllamaCloudConfigured } from '../ollama-cloud';
import {
  isWorkerRunning,
  startQueueWorker,
  stopQueueWorker,
  triggerProcessing,
} from '../queue-worker';

describe('queue-worker', () => {
  beforeEach(() => {
    vi.resetAllMocks();
    vi.useFakeTimers();
    stopQueueWorker(); // Ensure clean state
  });

  afterEach(() => {
    stopQueueWorker();
    vi.useRealTimers();
  });

  describe('startQueueWorker', () => {
    it('starts the worker when enabled', () => {
      vi.mocked(isOllamaCloudConfigured).mockReturnValue(true);
      vi.mocked(aiQueueRepository.findPending).mockResolvedValue(null);

      startQueueWorker();

      expect(isWorkerRunning()).toBe(true);
    });

    it('does not start twice', () => {
      vi.mocked(isOllamaCloudConfigured).mockReturnValue(true);
      vi.mocked(aiQueueRepository.findPending).mockResolvedValue(null);

      startQueueWorker();
      startQueueWorker();

      expect(isWorkerRunning()).toBe(true);
    });
  });

  describe('stopQueueWorker', () => {
    it('stops the worker', () => {
      vi.mocked(isOllamaCloudConfigured).mockReturnValue(true);
      vi.mocked(aiQueueRepository.findPending).mockResolvedValue(null);

      startQueueWorker();
      expect(isWorkerRunning()).toBe(true);

      stopQueueWorker();
      expect(isWorkerRunning()).toBe(false);
    });
  });

  describe('triggerProcessing', () => {
    it('returns processed: false when no pending jobs', async () => {
      vi.mocked(isOllamaCloudConfigured).mockReturnValue(true);
      vi.mocked(aiQueueRepository.findPending).mockResolvedValue(null);

      const result = await triggerProcessing();

      expect(result).toEqual({ processed: false });
    });

    it('returns processed: false when not configured', async () => {
      vi.mocked(isOllamaCloudConfigured).mockReturnValue(false);

      const result = await triggerProcessing();

      expect(result).toEqual({ processed: false });
    });

    it('processes a job successfully', async () => {
      const mockJob = {
        id: 'job-1',
        userId: 'user-1',
        requestType: 'post_generation',
        inputData: { prompt: 'Test prompt' },
        status: 'pending',
        result: null,
        errorMessage: null,
        attempts: 0,
        maxAttempts: 3,
        createdAt: new Date(),
        processedAt: null,
      };

      vi.mocked(isOllamaCloudConfigured).mockReturnValue(true);
      vi.mocked(aiQueueRepository.findPending).mockResolvedValue(mockJob);
      vi.mocked(aiQueueRepository.markProcessing).mockResolvedValue({ ...mockJob, attempts: 1 });
      vi.mocked(generate).mockResolvedValue({
        success: true,
        data: {
          response: 'Generated text',
          model: 'deepseek-v3.2',
          created_at: '2024-01-01',
          done: true,
          prompt_eval_count: 10,
          eval_count: 20,
        },
      });
      vi.mocked(aiQueueRepository.markCompleted).mockResolvedValue({
        ...mockJob,
        status: 'completed',
      });

      const result = await triggerProcessing();

      expect(result).toEqual({ processed: true, jobId: 'job-1' });
      expect(aiQueueRepository.markProcessing).toHaveBeenCalledWith('job-1');
      expect(aiQueueRepository.markCompleted).toHaveBeenCalledWith('job-1', expect.objectContaining({
        response: 'Generated text',
      }));
    });

    it('marks job as failed after max attempts', async () => {
      const mockJob = {
        id: 'job-1',
        userId: 'user-1',
        requestType: 'post_generation',
        inputData: { prompt: 'Test prompt' },
        status: 'pending',
        result: null,
        errorMessage: null,
        attempts: 2,
        maxAttempts: 3,
        createdAt: new Date(),
        processedAt: null,
      };

      vi.mocked(isOllamaCloudConfigured).mockReturnValue(true);
      vi.mocked(aiQueueRepository.findPending).mockResolvedValue(mockJob);
      vi.mocked(aiQueueRepository.markProcessing).mockResolvedValue({ ...mockJob, attempts: 3 });
      vi.mocked(generate).mockResolvedValue({
        success: false,
        error: { code: 'RATE_LIMITED', message: 'Rate limit exceeded' },
      });
      vi.mocked(aiQueueRepository.findById).mockResolvedValue({ ...mockJob, attempts: 3 });
      vi.mocked(aiQueueRepository.markFailed).mockResolvedValue({ ...mockJob, status: 'failed' });

      await triggerProcessing();

      expect(aiQueueRepository.markFailed).toHaveBeenCalledWith('job-1', 'Rate limit exceeded');
    });

    it('resets job to pending for retry when under max attempts', async () => {
      const mockJob = {
        id: 'job-1',
        userId: 'user-1',
        requestType: 'post_generation',
        inputData: { prompt: 'Test prompt' },
        status: 'pending',
        result: null,
        errorMessage: null,
        attempts: 0,
        maxAttempts: 3,
        createdAt: new Date(),
        processedAt: null,
      };

      vi.mocked(isOllamaCloudConfigured).mockReturnValue(true);
      vi.mocked(aiQueueRepository.findPending).mockResolvedValue(mockJob);
      vi.mocked(aiQueueRepository.markProcessing).mockResolvedValue({ ...mockJob, attempts: 1 });
      vi.mocked(generate).mockResolvedValue({
        success: false,
        error: { code: 'RATE_LIMITED', message: 'Rate limit exceeded' },
      });
      vi.mocked(aiQueueRepository.findById).mockResolvedValue({ ...mockJob, attempts: 1 });
      vi.mocked(aiQueueRepository.resetToPending).mockResolvedValue({ ...mockJob, status: 'pending' });

      await triggerProcessing();

      expect(aiQueueRepository.resetToPending).toHaveBeenCalledWith('job-1');
    });
  });
});
```

**Step 2: Run tests**

Run: `pnpm --filter=@repo/admin test`
Expected: All tests PASS

**Step 3: Commit**

```bash
git add apps/admin/lib/ai/__tests__/queue-worker.test.ts
git commit -m "test(ai): add unit tests for queue worker"
```

---

## Task 11: Final Verification

**Step 1: Run all checks**

```bash
cd /home/wandeon/WebVB
pnpm type-check
pnpm lint --filter=@repo/admin
pnpm --filter=@repo/admin test
pnpm build
```

Expected: All commands pass

**Step 2: Verify directory structure**

```bash
ls -la apps/admin/lib/ai/
ls -la apps/admin/app/api/ai/queue/
ls -la apps/admin/app/\(dashboard\)/ai/
```

**Step 3: Manual test (when Ollama quota resets)**

1. Start admin app: `pnpm dev --filter=@repo/admin`
2. Navigate to /ai in admin panel
3. Verify stats show (worker running, Ollama configured)
4. Submit a test job via API:
```bash
curl -X POST http://localhost:3001/api/ai/queue \
  -H "Content-Type: application/json" \
  -H "Cookie: <session-cookie>" \
  -d '{"requestType":"post_generation","prompt":"Napiši kratku vijest o otvaranju novog parka."}'
```
5. Watch the /ai page - job should move from pending → processing → completed
6. Check result in job details

---

## Summary

| Task | Description |
|------|-------------|
| 1 | AI Queue repository |
| 2 | Queue worker with polling |
| 3 | Start worker on app boot |
| 4 | Queue API routes (submit & list) |
| 5 | Single job & cancel API routes |
| 6 | Queue stats API route |
| 7 | Manual process trigger API |
| 8 | Admin queue status page |
| 9 | Add AI to sidebar navigation |
| 10 | Unit tests for queue worker |
| 11 | Final verification |

## Files Created/Modified

**Created:**
- `packages/database/src/repositories/ai-queue.ts` - Repository
- `apps/admin/lib/ai/queue-worker.ts` - Background worker
- `apps/admin/instrumentation.ts` - Worker startup
- `apps/admin/app/api/ai/queue/route.ts` - Submit & list
- `apps/admin/app/api/ai/queue/[id]/route.ts` - Get & cancel
- `apps/admin/app/api/ai/queue/stats/route.ts` - Statistics
- `apps/admin/app/api/ai/queue/process/route.ts` - Manual trigger
- `apps/admin/app/(dashboard)/ai/page.tsx` - Admin page
- `apps/admin/app/(dashboard)/ai/ai-queue-status.tsx` - Status component
- `apps/admin/lib/ai/__tests__/queue-worker.test.ts` - Tests

**Modified:**
- `packages/database/src/repositories/index.ts` - Export repository
- `apps/admin/lib/ai/index.ts` - Export worker functions
- `apps/admin/config/navigation.ts` - Add AI to sidebar

## Next Sprint

Sprint 6.3: Google Search integration - context gathering for AI content generation.
